- https://trungtran.io/2019/04/29/create-the-transformer-with-tensorflow-2-0/ : Architecture du Transformer
- https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ : Explication du Positional Encoding
- https://arxiv.org/pdf/1706.03762.pdf#page=11&zoom=100,150,176 : Attention is All You Need
- https://arxiv.org/ftp/arxiv/papers/2008/2008.04057.pdf : Utilisation de GPT seulement pour échecs
- https://theaisummer.com/transformer/ : Une explication des transformers
- https://fr.wikipedia.org/wiki/Nombre_de_Shannon : Nombre de coups possibles par tour = 218 ==> Faux finalement
- https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0 : Explication step by step
- https://jalammar.github.io/illustrated-gpt2/ : Explication GPT


Possiblement utile pour recoder transformer :
- https://www.tensorflow.org/text/tutorials/transformer
- https://github.com/valentingol/ : Code de Valentin qui m'a beaucoup aidé